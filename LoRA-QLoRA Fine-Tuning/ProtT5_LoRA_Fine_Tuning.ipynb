{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ProtT5 models fine-tuning with LoRA for Antimicrobial Peptides (AMP) Classification\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates the process of:\n",
        "1. Fine-tuning ProtT5 models with Low-Rank Adaptation (LoRA) to perform AMP classification (AMP vs non-AMP ).\n",
        "2. Evaluating the model's performance using metrics such as accuracy, precision, recall, F1-score, ROC AUC, and Matthews correlation coefficient (MCC)."
      ],
      "metadata": {
        "id": "oGVmmWIxs8O4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acknowledgment\n",
        "\n",
        "The implementation of Low-Rank Adaptation (LoRA) and the model adaptation code used in this notebook have been adapted from the work by Robert Schmirler et al. The original repository can be found at:\n",
        "\n",
        "- [GitHub Repository: PLM Fine-Tuning Evaluation](https://github.com/RSchmirler/data-repo_plm-finetune-eval)\n"
      ],
      "metadata": {
        "id": "XopZ87o8s_5P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_jKZ8MSiTxV"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install datasets evaluate==0.4.0 biopython datasets wandb transformers peft\n",
        "!pip install -U bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import os.path\n",
        "from Bio import SeqIO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import transformers, datasets\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n",
        "from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n",
        "from transformers import T5EncoderModel, T5Tokenizer\n",
        "from transformers import TrainingArguments, Trainer, set_seed\n",
        "from peft import get_peft_config, PeftConfig, inject_adapter_in_model, LoraConfig\n",
        "from evaluate import load\n",
        "from datasets import Dataset\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, matthews_corrcoef"
      ],
      "metadata": {
        "id": "Lu9UvwvTjLJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions for Data Loading and Processing"
      ],
      "metadata": {
        "id": "HRFmxxb1-9kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fasta(file_path):\n",
        "    \"\"\"\n",
        "    Load sequences from a FASTA file and return them in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the FASTA file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing 'seq_id' and 'sequence'.\n",
        "    \"\"\"\n",
        "    with open(os.path.abspath(file_path)) as fasta_file:\n",
        "        seq_ids, sequences = [], []\n",
        "        for seq_record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "            sequences.append(str(seq_record.seq))\n",
        "            seq_ids.append(seq_record.id)\n",
        "    data = pd.DataFrame({\"seq_id\": seq_ids, \"sequence\": sequences})\n",
        "    data.drop_duplicates(inplace=True)\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "Z-L1KTRb_DAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sequences(data):\n",
        "    \"\"\"\n",
        "    Preprocess sequences by separating letters and replacing invalid characters.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): DataFrame containing sequences.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with 'Separated' and 'Processed' columns.\n",
        "    \"\"\"\n",
        "    def process_sequence(sequence):\n",
        "        # Separate letters with spaces and replace invalid characters\n",
        "        separated = ' '.join(sequence)\n",
        "        processed = re.sub(r\"[UZOB]\", \"X\", separated)\n",
        "        return separated, processed\n",
        "\n",
        "    # Apply preprocessing to each sequence\n",
        "    data[['Separated', 'Processed']] = data['sequence'].apply(\n",
        "        lambda seq: pd.Series(process_sequence(seq))\n",
        "    )\n",
        "    return data\n",
        "\n",
        "\n",
        "def prepare_dataset_with_preprocessing(amp_fasta, non_amp_fasta):\n",
        "    \"\"\"\n",
        "    Prepare datasets by loading and preprocessing AMP and non-AMP sequences.\n",
        "\n",
        "    Args:\n",
        "        amp_fasta (str): Path to the AMP FASTA file.\n",
        "        non_amp_fasta (str): Path to the non-AMP FASTA file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (data, labels) where:\n",
        "            - data (pd.DataFrame): Contains seq_id, sequence, Separated, and Processed columns.\n",
        "            - labels (list of int): Binary labels (1 for AMP, 0 for non-AMP).\n",
        "    \"\"\"\n",
        "    amp_data = load_fasta(amp_fasta)\n",
        "    non_amp_data = load_fasta(non_amp_fasta)\n",
        "\n",
        "    # Preprocess the sequences\n",
        "    amp_data = preprocess_sequences(amp_data)\n",
        "    non_amp_data = preprocess_sequences(non_amp_data)\n",
        "\n",
        "    # Combine data and create labels\n",
        "    data = pd.concat([amp_data, non_amp_data], ignore_index=True)\n",
        "    labels = [1] * len(amp_data) + [0] * len(non_amp_data)\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "k9Qw8rBuvNNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oa4SxVpZSJ_"
      },
      "source": [
        "### Data Preparation\n",
        "Loading and processing training and test datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tUPXQv3G2Pb"
      },
      "outputs": [],
      "source": [
        "# File paths for training and validation data\n",
        "\n",
        "# Train datasets\n",
        "train_amp_fasta = \"/path/to/your/folder/DRAMP_pretrain_train_positive.fasta\"\n",
        "train_non_amp_fasta = \"/path/to/your/folder/DRAMP_pretrain_train_negative.fasta\"\n",
        "\n",
        "# Validation datasets\n",
        "val_amp_fasta = \"/path/to/your/folder/DRAMP_pretrain_val_positive.fasta\"\n",
        "val_non_amp_fasta = \"/path/to/your/folder/DRAMP_pretrain_val_negative.fasta\"\n",
        "\n",
        "# Test datasets\n",
        "test_amp_fasta = \"/path/to/your/folder/DRAMP_AMP.fasta\"\n",
        "test_non_amp_fasta = \"/path/to/your/folder/DRAMP_nonAMP.fasta\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kawQhLMpH2iD",
        "outputId": "67a22126-40ad-48c5-88c8-07c9a44b5a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Processed Training Data:\n",
            "            seq_id                                           sequence  \\\n",
            "0       DRAMP02197  MFTMKKSLLLFFFLGTISLSLCEEERGADEDDGVELTEEEVKRGLL...   \n",
            "1       AMPfun_779                                       GATPEDLNQKLS   \n",
            "2        ADAM_1998                       GIMDSVKGLAKNLAGKLLDSLKCKITGC   \n",
            "3        ADAM_5276                         RFRLPFRRPPIRIHPPPFYPPFRRFL   \n",
            "4  LAMP_L01A001891     KGLKKDSDFRRVGISVSKKVGKAITRNRVRRLIKEKIKDIVFIKNL   \n",
            "\n",
            "                                           Separated  \\\n",
            "0  M F T M K K S L L L F F F L G T I S L S L C E ...   \n",
            "1                            G A T P E D L N Q K L S   \n",
            "2  G I M D S V K G L A K N L A G K L L D S L K C ...   \n",
            "3  R F R L P F R R P P I R I H P P P F Y P P F R ...   \n",
            "4  K G L K K D S D F R R V G I S V S K K V G K A ...   \n",
            "\n",
            "                                           Processed  \n",
            "0  M F T M K K S L L L F F F L G T I S L S L C E ...  \n",
            "1                            G A T P E D L N Q K L S  \n",
            "2  G I M D S V K G L A K N L A G K L L D S L K C ...  \n",
            "3  R F R L P F R R P P I R I H P P P F Y P P F R ...  \n",
            "4  K G L K K D S D F R R V G I S V S K K V G K A ...  \n"
          ]
        }
      ],
      "source": [
        "# Prepare datasets\n",
        "train_sequences, train_labels = prepare_dataset_with_preprocessing(train_amp_fasta, train_non_amp_fasta)\n",
        "validation_sequences, validation_labels = prepare_dataset_with_preprocessing(val_amp_fasta, val_non_amp_fasta)\n",
        "test_sequences, test_labels = prepare_dataset_with_preprocessing(test_amp_fasta, test_non_amp_fasta)\n",
        "\n",
        "# Display sample processed data\n",
        "print(\"Sample Processed Training Data:\")\n",
        "print(train_sequences.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Classes and Functions\n",
        "- **`ClassConfig`**: Configuration function for model's calssification head.\n",
        "- **`T5EncoderClassificationHead`**: Custom classification head for ProtT5 models.\n",
        "- **`T5EncoderForSimpleSequenceClassification`**: Custom ProtT5 encoder model with a classification head.\n",
        "- **`inject_adapter_in_model`**: LoRA-based parameter adaptation."
      ],
      "metadata": {
        "id": "q4IFmDBQTJvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassConfig:\n",
        "    def __init__(self, dropout=0.2, num_labels=2):\n",
        "        self.dropout_rate = dropout\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "class T5EncoderClassificationHead(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, config, class_config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
        "        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "\n",
        "        hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n",
        "\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = torch.tanh(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.out_proj(hidden_states)\n",
        "        return hidden_states"
      ],
      "metadata": {
        "id": "_72CDWAUt3am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n",
        "\n",
        "    def __init__(self, config: T5Config, class_config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = class_config.num_labels\n",
        "        self.config = config\n",
        "\n",
        "        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n",
        "\n",
        "        encoder_config = copy.deepcopy(config)\n",
        "        encoder_config.use_cache = False\n",
        "        encoder_config.is_encoder_decoder = False\n",
        "        self.encoder = T5Stack(encoder_config, self.shared)\n",
        "\n",
        "        self.dropout = nn.Dropout(class_config.dropout_rate)\n",
        "        self.classifier = T5EncoderClassificationHead(config, class_config)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "        # Model parallel\n",
        "        self.model_parallel = False\n",
        "        self.device_map = None\n",
        "\n",
        "    def parallelize(self, device_map=None):\n",
        "        self.device_map = (\n",
        "            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n",
        "            if device_map is None\n",
        "            else device_map\n",
        "        )\n",
        "        assert_device_map(self.device_map, len(self.encoder.block))\n",
        "        self.encoder.parallelize(self.device_map)\n",
        "        self.classifier = self.classifier.to(self.encoder.first_device)\n",
        "        self.model_parallel = True\n",
        "\n",
        "    def deparallelize(self):\n",
        "        self.encoder.deparallelize()\n",
        "        self.encoder = self.encoder.to(\"cpu\")\n",
        "        self.model_parallel = False\n",
        "        self.device_map = None\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.shared\n",
        "\n",
        "    def set_input_embeddings(self, new_embeddings):\n",
        "        self.shared = new_embeddings\n",
        "        self.encoder.set_input_embeddings(new_embeddings)\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder\n",
        "\n",
        "    def _prune_heads(self, heads_to_prune):\n",
        "        \"\"\"\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
        "        class PreTrainedModel\n",
        "        \"\"\"\n",
        "        for layer, heads in heads_to_prune.items():\n",
        "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        hidden_states = outputs[0]\n",
        "        logits = self.classifier(hidden_states)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ],
      "metadata": {
        "id": "oN7aLFQcl8cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model and Tokenizer Loading"
      ],
      "metadata": {
        "id": "Ks88Wd-jTzdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ProtT5 Model Versions Table\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "html_table_prott5 = \"\"\"\n",
        "<style>\n",
        "    table {\n",
        "        font-family: Arial, sans-serif;\n",
        "        border-collapse: collapse;\n",
        "        width: 80%;\n",
        "        margin: auto;\n",
        "        font-size: 16px;\n",
        "    }\n",
        "    th, td {\n",
        "        border: 1px solid #dddddd;\n",
        "        text-align: center;\n",
        "        padding: 8px;\n",
        "    }\n",
        "    th {\n",
        "        background-color: #f2f2f2;\n",
        "        color: #333;\n",
        "    }\n",
        "    tr:nth-child(even) {\n",
        "        background-color: #f9f9f9;\n",
        "    }\n",
        "    tr:hover {\n",
        "        background-color: #f1f1f1;\n",
        "    }\n",
        "</style>\n",
        "<table>\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th>ProtT5 Model Version (Shorthand)</th>\n",
        "            <th># Params</th>\n",
        "            <th>Embedding Dim</th>\n",
        "            <th>Training Dataset</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td>prot_t5_xl_half_uniref50-enc (xl_half)</td>\n",
        "            <td>3B</td>\n",
        "            <td>1024</td>\n",
        "            <td>UniRef50</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>prot_t5_xl_bfd (xl_bfd)</td>\n",
        "            <td>3B</td>\n",
        "            <td>1024</td>\n",
        "            <td>BFD</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>prot_t5_xl_uniref50 (xl_uni)</td>\n",
        "            <td>3B</td>\n",
        "            <td>1024</td>\n",
        "            <td>UniRef50</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>prot_t5_xxl_bfd (xxl_bfd)</td>\n",
        "            <td>11B</td>\n",
        "            <td>1024</td>\n",
        "            <td>BFD</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>prot_t5_xxl_uniref50 (xxl_uni)</td>\n",
        "            <td>11B</td>\n",
        "            <td>1024</td>\n",
        "            <td>UniRef50</td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_table_prott5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "cellView": "form",
        "id": "Rp3NZlYNWP8L",
        "outputId": "2b0cc457-1215-4f36-f221-290c24c51e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    table {\n",
              "        font-family: Arial, sans-serif;\n",
              "        border-collapse: collapse;\n",
              "        width: 80%;\n",
              "        margin: auto;\n",
              "        font-size: 16px;\n",
              "    }\n",
              "    th, td {\n",
              "        border: 1px solid #dddddd;\n",
              "        text-align: center;\n",
              "        padding: 8px;\n",
              "    }\n",
              "    th {\n",
              "        background-color: #f2f2f2;\n",
              "        color: #333;\n",
              "    }\n",
              "    tr:nth-child(even) {\n",
              "        background-color: #f9f9f9;\n",
              "    }\n",
              "    tr:hover {\n",
              "        background-color: #f1f1f1;\n",
              "    }\n",
              "</style>\n",
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>ProtT5 Model Version (Shorthand)</th>\n",
              "            <th># Params</th>\n",
              "            <th>Embedding Dim</th>\n",
              "            <th>Training Dataset</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>prot_t5_xl_half_uniref50-enc (xl_half)</td>\n",
              "            <td>3B</td>\n",
              "            <td>1024</td>\n",
              "            <td>UniRef50</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>prot_t5_xl_bfd (xl_bfd)</td>\n",
              "            <td>3B</td>\n",
              "            <td>1024</td>\n",
              "            <td>BFD</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>prot_t5_xl_uniref50 (xl_uni)</td>\n",
              "            <td>3B</td>\n",
              "            <td>1024</td>\n",
              "            <td>UniRef50</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>prot_t5_xxl_bfd (xxl_bfd)</td>\n",
              "            <td>11B</td>\n",
              "            <td>1024</td>\n",
              "            <td>BFD</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>prot_t5_xxl_uniref50 (xxl_uni)</td>\n",
              "            <td>11B</td>\n",
              "            <td>1024</td>\n",
              "            <td>UniRef50</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ProtT5 model and tokenizer\n",
        "def load_T5_model(model_variant, num_labels):\n",
        "    \"\"\"\n",
        "    Load a specified ProtT5 model variant using shorthand names.\n",
        "\n",
        "    Args:\n",
        "        model_variant (str): Shorthand for the ProtT5 model variant to load. Options are:\n",
        "                             't5_xl', 't5_xl_bfd', 't5_xxl', 't5_xxl_bfd'.\n",
        "        num_labels (int): Number of labels for the classification task.\n",
        "\n",
        "    Returns:\n",
        "        model: The loaded ProtT5 model.\n",
        "        tokenizer: The corresponding tokenizer for the model.\n",
        "    \"\"\"\n",
        "    # Define model checkpoints mapped to shorthand names\n",
        "    model_checkpoints = {\n",
        "        \"xl_half\": \"Rostlab/prot_t5_xl_half_uniref50-enc\",\n",
        "        \"xl_bfd\": \"Rostlab/prot_t5_xl_bfd\",\n",
        "        \"xl_uni\": \"Rostlab/prot_t5_xl_uniref50\",\n",
        "        \"xxl_bfd\": \"Rostlab/prot_t5_xxl_bfd\",\n",
        "        \"xxl_uni\": \"Rostlab/prot_t5_xxl_uniref50\",\n",
        "    }\n",
        "\n",
        "    # Validate the model_variant input\n",
        "    if model_variant not in model_checkpoints:\n",
        "        raise ValueError(f\"Invalid model variant '{model_variant}'. \"\n",
        "                         f\"Choose from {list(model_checkpoints.keys())}.\")\n",
        "\n",
        "    # Load the tokenizer\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_checkpoints[model_variant], do_lower_case=False)\n",
        "\n",
        "    # Load the model\n",
        "    model = T5EncoderModel.from_pretrained(model_checkpoints[model_variant])\n",
        "\n",
        "    return model, tokenizer\n"
      ],
      "metadata": {
        "id": "wXuKrHyIl8cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model, tokenizer = load_T5_model('xl_uni', num_labels=2)"
      ],
      "metadata": {
        "id": "1HVbsCycnzIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenizing and Formatting Data\n",
        "\n",
        "Tokenize train/validation/test datasets and prepare them for LoRA fine-tuning."
      ],
      "metadata": {
        "id": "qvHayJStczQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(tokenizer, processed_data, labels):\n",
        "    \"\"\"\n",
        "    Tokenizes preprocessed sequences and creates a Hugging Face Dataset for model input.\n",
        "\n",
        "    Args:\n",
        "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer corresponding to the model.\n",
        "        processed_data (pd.DataFrame): DataFrame containing preprocessed sequences\n",
        "                                       in the 'Processed' column (output of `preprocess_sequences`).\n",
        "        labels (list of int): List of labels corresponding to the sequences.\n",
        "\n",
        "    Returns:\n",
        "        datasets.Dataset: A Hugging Face Dataset object containing tokenized input_ids,\n",
        "                          attention masks, and labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract processed sequences\n",
        "    sequences = processed_data['Processed'].tolist()\n",
        "\n",
        "    # Tokenize the sequences with padding and truncation\n",
        "    tokenized = tokenizer(sequences, padding=True, truncation=True, max_length=1024)\n",
        "\n",
        "    # Create a Hugging Face Dataset with input_ids, attention masks, and labels\n",
        "    dataset = Dataset.from_dict({\n",
        "        'input_ids': tokenized['input_ids'],\n",
        "        'attention_mask': tokenized['attention_mask'],\n",
        "        'labels': labels\n",
        "    })\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "8yLSa74i2E9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train, validation, and test datasets\n",
        "train_dataset = create_dataset(tokenizer, train_sequences, train_labels)\n",
        "validation_dataset = create_dataset(tokenizer, validation_sequences, validation_labels)\n",
        "test_dataset = create_dataset(tokenizer, test_sequences, test_labels)"
      ],
      "metadata": {
        "id": "G5WuXk1slo5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configuration and LoRA Setup"
      ],
      "metadata": {
        "id": "OPxgUN1jUItR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    learning_rate=0.001,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=1, # Increase this value to simulate a larger effective batch size\n",
        "                                   # when GPU memory is limited. Reduce per-device batch size accordingly.\n",
        "    save_safetensors=False,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJHtnDMsoheY",
        "outputId": "8e6131e9-ce58-4322-9b7e-e5dab13274ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility of your trainings run\n",
        "def set_seeds(s):\n",
        "    torch.manual_seed(s)\n",
        "    np.random.seed(s)\n",
        "    random.seed(s)\n",
        "    set_seed(s)\n",
        "\n",
        "set_seeds(4)"
      ],
      "metadata": {
        "id": "la0VHiOdjqQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new Classifier model with PT5 dimensions\n",
        "class_config=ClassConfig(num_labels=2, dropout=0.1)\n",
        "class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n",
        "\n",
        "# Set encoder and embedding weights to checkpoint weights\n",
        "class_model.shared=model.shared\n",
        "class_model.encoder=model.encoder\n",
        "\n",
        "# Delete the checkpoint model\n",
        "model = class_model\n",
        "del class_model"
      ],
      "metadata": {
        "id": "rWLpgmxNo2lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=1,\n",
        "    lora_alpha=1.0,\n",
        "    bias=\"lora_only\",\n",
        "    target_modules=[\"q\",\"k\",\"v\",\"o\"],\n",
        "    lora_dropout=0.1\n",
        ")\n",
        "\n",
        "model = inject_adapter_in_model(peft_config, model)\n",
        "\n",
        "# Unfreeze the prediction head\n",
        "for (param_name, param) in model.classifier.named_parameters():\n",
        "            param.requires_grad = True"
      ],
      "metadata": {
        "id": "MgCzPSYzo2oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom compute_metrics for the trainer\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    roc_auc = roc_auc_score(labels, logits[:, 1]) if len(np.unique(labels)) == 2 else float('nan')\n",
        "    mcc = matthews_corrcoef(labels, predictions)\n",
        "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'mcc': mcc, 'roc_auc': roc_auc}"
      ],
      "metadata": {
        "id": "ME1w-dsK2umF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSufKSVKrm-r",
        "outputId": "828aff4c-56c7-4875-a432-f041f3ac20e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-320305828fa6>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "C70mFxHsUmWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate and save results\n",
        "predictions = trainer.predict(test_dataset)\n",
        "logits = predictions.predictions\n",
        "probabilities = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "metrics = compute_metrics((logits, predictions.label_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "xfJJbJ7VUsiY",
        "outputId": "f02016bb-ba93-4db8-dc9e-0d59ea955e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2380' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2380/2380 21:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.151771</td>\n",
              "      <td>0.940095</td>\n",
              "      <td>0.935065</td>\n",
              "      <td>0.950254</td>\n",
              "      <td>0.942598</td>\n",
              "      <td>0.880094</td>\n",
              "      <td>0.985296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.182600</td>\n",
              "      <td>0.200227</td>\n",
              "      <td>0.936942</td>\n",
              "      <td>0.913876</td>\n",
              "      <td>0.969543</td>\n",
              "      <td>0.940887</td>\n",
              "      <td>0.875199</td>\n",
              "      <td>0.988226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.110900</td>\n",
              "      <td>0.189685</td>\n",
              "      <td>0.945875</td>\n",
              "      <td>0.936634</td>\n",
              "      <td>0.960406</td>\n",
              "      <td>0.948371</td>\n",
              "      <td>0.891824</td>\n",
              "      <td>0.988763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>0.221844</td>\n",
              "      <td>0.945349</td>\n",
              "      <td>0.935707</td>\n",
              "      <td>0.960406</td>\n",
              "      <td>0.947896</td>\n",
              "      <td>0.890792</td>\n",
              "      <td>0.987801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.229537</td>\n",
              "      <td>0.950604</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.960406</td>\n",
              "      <td>0.952669</td>\n",
              "      <td>0.901155</td>\n",
              "      <td>0.988284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print metrics on test set\n",
        "pprint(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5iODRo_VDCW",
        "outputId": "a1ffbaff-693f-4138-ecf7-1824aac9fbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.7926136363636364,\n",
            " 'f1': 0.7523324851569126,\n",
            " 'mcc': 0.618884476415949,\n",
            " 'precision': 0.9336842105263158,\n",
            " 'recall': 0.6299715909090909,\n",
            " 'roc_auc': 0.8593520487635589}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate predictions\n",
        "predicted_labels = np.argmax(logits, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(predictions.label_ids, predicted_labels)\n",
        "\n",
        "# Display the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-AMP\", \"AMP\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "q_Nh7BROVKs_",
        "outputId": "9fc27c7a-12a1-494e-99ee-e35c9887c9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}